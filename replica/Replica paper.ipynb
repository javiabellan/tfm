{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress\n",
    "\n",
    "- **Datasets**\n",
    "  - [x] Read HIS2828 dataset\n",
    "  - [x] Read ISIC2017 dataset\n",
    "- **Tradicional features**\n",
    "  - [ ] Color moment features\n",
    "  - [ ] Texture features\n",
    "  - [ ] SVM with tradicional features only\n",
    "- **Deep features**: Coding network (CNN)\n",
    "  - [x] Create network architecture\n",
    "  - [ ] Train\n",
    "- **Fusion methods**\n",
    "  - [ ] CNMP (multilayer perceptron as fusion method)\n",
    "  - [ ] R feature fusion (manully fixed parameter)\n",
    "  - [ ] KPCA feature fusion\n",
    "  - [ ] SVM feature fusion (SVM as fusion method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIS2828 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2828 images in the dataset.\n"
     ]
    }
   ],
   "source": [
    "class HistologyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tdata_dir_hdd = pathlib.Path(\"D:/Datasets/TFM/histologyDS2828\")\n",
    "\t\tcsv_file     = data_dir_hdd / \"imageClasses.txt\"\n",
    "\t\tcsv_df       = pd.read_csv(csv_file, header=None, delim_whitespace=True, names=['Image', 'Label'])\n",
    "\t\tmean         = [0.485, 0.456, 0.406] #[0.5, 0.5, 0.5]\n",
    "\t\tstd          = [0.229, 0.224, 0.225] #[0.5, 0.5, 0.5]\n",
    "        \n",
    "\t\tself.image_dir  = data_dir_hdd / \"imgs\"\n",
    "\t\tself.images     = (csv_df[\"Image\"]).values\n",
    "\t\tself.labels     = (csv_df[\"Label\"]-1).values\n",
    "\t\tself.labels_map = {0: \"conective tissue\", 1: \"ephitelial tissue\", 2: \"muscular tissue\", 3: \"nervous tissue\"}\n",
    "\t\tself.transforms = transforms.Compose([transforms.RandomCrop(420),\n",
    "                                              transforms.Resize(140),\n",
    "                                              transforms.RandomHorizontalFlip(),\n",
    "                                              transforms.RandomVerticalFlip(),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize(mean, std)])\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.labels)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_name = self.image_dir / self.images[idx]\n",
    "\t\timage = PIL.Image.open(img_name)\n",
    "\t\tif self.transforms: image = self.transforms(image)\n",
    "\t\tlabel = self.labels[idx]\n",
    "\t\treturn image, label\n",
    "    \n",
    "micro_ds    = HistologyDataset()\n",
    "print(\"There are\", len(micro_ds), \"images in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISIC2017 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2000 images in the train dataset.\n",
      "There are 150 images in the valid dataset.\n",
      "There are 600 images in the test dataset.\n"
     ]
    }
   ],
   "source": [
    "class SkinDataset(torch.utils.data.Dataset):\n",
    "\n",
    "\tdef __init__(self, subset, transforms=False):\n",
    "\t\tdataset_dir = pathlib.Path(\"D:/Datasets/TFM/ISIC-2017\")\n",
    "\t\tcsv_file    = dataset_dir / (\"ground_truth_\"+subset+\".csv\")\n",
    "\t\tcsv_df      = pd.read_csv(csv_file)\n",
    "\n",
    "\t\tself.image_dir  = dataset_dir / (\"data_\"+subset)\n",
    "\t\tself.images     = (csv_df[\"image_id\"]+\".jpg\").values\n",
    "\t\tself.labels1    = (csv_df[\"melanoma\"]).values\n",
    "\t\tself.labels2    = (csv_df[\"seborrheic_keratosis\"]).values\n",
    "\t\tself.labels_map = {0:\"melanoma\", 1:\"seborrheic\", 2:\"healthy\"}\n",
    "\t\tself.transforms = transforms\n",
    "        \n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.labels1)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_name = self.image_dir / self.images[idx]\n",
    "\t\timage = PIL.Image.open(img_name)\n",
    "\t\tif self.transforms: image = self.transforms(image)\n",
    "\t\tlabel = self.labels1[idx]\n",
    "\t\treturn image, label\n",
    "\n",
    "skin_ds    = {subset: SkinDataset(subset) for subset in [\"train\", \"valid\", \"test\"]}\n",
    "{print(\"There are\", len(skin_ds[subset]), \"images in the \"+subset+\" dataset.\") for subset in [\"train\", \"valid\", \"test\"]};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Network architecture\n",
    "\n",
    "Input size of `3×140×140`\n",
    "\n",
    "Layer       | Kernel | Stride | Output size\n",
    "------------|--------|--------|------------\n",
    "Convolution | 11×11  |    1   | 32×130×130\n",
    "Convolution | 11×11  |    1   | 32×120×120\n",
    "Max pooling | 5×5    |    2   | 32×58×58\n",
    "Convolution | 9×9    |    1   | 64×50×50\n",
    "Max pooling | 5×5    |    2   | 64×23×23\n",
    "Convolution | 8×8    |    1   | 128×16×16\n",
    "Convolution | 9×9    |    1   | 256×8×8\n",
    "Convolution | 8×8    |    1   | 256×1×1\n",
    "Dense       |    -   |    -   | 4×1×1\n",
    "Softmax     |    -   |    -   | 4×1×1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4])\n"
     ]
    }
   ],
   "source": [
    "class CodingNetwork(nn.Module):\n",
    "    \n",
    "    #Our batch shape for input x is (3, 140, 140)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CodingNetwork, self).__init__()\n",
    "        \n",
    "        #Input channels=3, output channels=32\n",
    "        self.conv1 = nn.Conv2d(3,  32, kernel_size=11, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=11, stride=1, padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=5, stride=2, padding=0)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=9, stride=1, padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=5, stride=2, padding=0)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=8, stride=1, padding=0)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=9, stride=1, padding=0)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=8, stride=1, padding=0)\n",
    "\n",
    "        #4608 input features, 64 output features (see sizing flow below)\n",
    "        self.fc = nn.Linear(256, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Computes the activation of the first convolution\n",
    "        \n",
    "        x = F.relu(self.conv1(x)) # Size changes from (3, 140, 140) to (32, 130, 130)\n",
    "        x = F.relu(self.conv2(x)) # Size changes from (32, 130, 130) to (32, 120, 120)\n",
    "        x = self.pool1(x)         # Size changes from (32, 120, 120) to (32, 58, 58)\n",
    "\n",
    "        x = F.relu(self.conv3(x)) # Size changes from (32, 58, 58) to (64, 50, 50)\n",
    "        x = self.pool2(x)         # Size changes from (64, 50, 50) to (64, 23, 23)\n",
    "\n",
    "        x = F.relu(self.conv4(x)) # Size changes from (64, 23, 23) to (128, 16, 16)\n",
    "        x = F.relu(self.conv5(x)) # Size changes from (128, 16, 16) to (256, 8, 8)\n",
    "        x = F.relu(self.conv6(x)) # Size changes from (256, 8, 8) to (256, 1, 1)\n",
    "\n",
    "        x = x.view(-1, 256)       # Size changes from (256, 1, 1) to (256)\n",
    "        x = self.fc(x)            # Size changes from (256) to (4)\n",
    "        \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CodingNetwork()\n",
    "\n",
    "x = torch.randn(16, 3, 140, 140)\n",
    "output = model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
