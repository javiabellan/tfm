{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replica paper skin\n",
    "### Progress\n",
    "\n",
    "- **Tradicional features**\n",
    "  - [x] Color moment features\n",
    "  - [x] Texture features\n",
    "  - [ ] SVM with tradicional features only\n",
    "- **Deep features**: Coding network (CNN)\n",
    "  - [x] Create network architecture\n",
    "  - [ ] Train\n",
    "- **Fusion methods**\n",
    "  - [ ] CNMP (multilayer perceptron as fusion method)\n",
    "  - [ ] R feature fusion (manully fixed parameter)\n",
    "  - [ ] KPCA feature fusion\n",
    "  - [ ] SVM feature fusion (SVM as fusion method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "from fastai.vision import *\n",
    "\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import skew, kurtosis                         # Color feature (3rd moment)\n",
    "from skimage.feature.texture import greycomatrix, greycoprops  # Texture features\n",
    "from skimage.measure import shannon_entropy                    # Texture features (entropy)\n",
    "from sklearn.svm import SVC                                    # Support vector machine\n",
    "from sklearn.model_selection import StratifiedKFold            # Stratified cross validation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIS2828 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2828 images in the dataset.\n"
     ]
    }
   ],
   "source": [
    "class HistologyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "\tdef __init__(self, transforms=False):\n",
    "\t\tdata_dir_hdd = pathlib.Path(\"E:/Datasets/TFM/histologyDS2828\")\n",
    "\t\tcsv_file     = data_dir_hdd / \"imageClasses.txt\"\n",
    "\t\tcsv_df       = pd.read_csv(csv_file, header=None, delim_whitespace=True, names=['Image', 'Label'])\n",
    "        \n",
    "\t\tself.image_dir  = data_dir_hdd / \"imgs\"\n",
    "\t\tself.images     = (csv_df[\"Image\"]).values\n",
    "\t\tself.labels     = (csv_df[\"Label\"]-1).values\n",
    "\t\tself.labels_map = {0: \"conective tissue\", 1: \"ephitelial tissue\", 2: \"muscular tissue\", 3: \"nervous tissue\"}\n",
    "\t\tself.transforms = transforms\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.labels)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_name = self.image_dir / self.images[idx]\n",
    "\t\timage = PIL.Image.open(img_name)\n",
    "\t\tif self.transforms: image = self.transforms(image)\n",
    "\t\tlabel = self.labels[idx]\n",
    "\t\treturn image, label\n",
    "\n",
    "mean       = [0.485, 0.456, 0.406] #[0.5, 0.5, 0.5]\n",
    "std        = [0.229, 0.224, 0.225] #[0.5, 0.5, 0.5]\n",
    "train_tmfs =  transforms.Compose([transforms.RandomCrop(420),\n",
    "                                  transforms.Resize(140),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.RandomVerticalFlip(),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean, std)])\n",
    "\n",
    "micro_ds = HistologyDataset()\n",
    "print(\"There are\", len(micro_ds), \"images in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISIC2017 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2000 images in the train dataset.\n",
      "There are 150 images in the valid dataset.\n",
      "There are 600 images in the test dataset.\n"
     ]
    }
   ],
   "source": [
    "class SkinDataset(torch.utils.data.Dataset):\n",
    "\n",
    "\tdef __init__(self, subset, transforms=False):\n",
    "\t\tdataset_dir = pathlib.Path(\"E:/Datasets/TFM/ISIC-2017\")\n",
    "\t\tcsv_file    = dataset_dir / (\"ground_truth_\"+subset+\".csv\")\n",
    "\t\tcsv_df      = pd.read_csv(csv_file)\n",
    "\n",
    "\t\tself.image_dir  = dataset_dir / (\"data_\"+subset)\n",
    "\t\tself.images     = (csv_df[\"image_id\"]+\".jpg\").values\n",
    "\t\tself.labels1    = (csv_df[\"melanoma\"]).values\n",
    "\t\tself.labels2    = (csv_df[\"seborrheic_keratosis\"]).values\n",
    "\t\tself.labels_map = {0:\"melanoma\", 1:\"seborrheic\", 2:\"healthy\"}\n",
    "\t\tself.transforms = transforms\n",
    "        \n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.labels1)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_name = self.image_dir / self.images[idx]\n",
    "\t\timage = PIL.Image.open(img_name)\n",
    "\t\tif self.transforms: image = self.transforms(image)\n",
    "\t\tlabel = self.labels1[idx]\n",
    "\t\treturn image, label\n",
    "\n",
    "skin_ds    = {subset: SkinDataset(subset) for subset in [\"train\", \"valid\", \"test\"]}\n",
    "{print(\"There are\", len(skin_ds[subset]), \"images in the \"+subset+\" dataset.\") for subset in [\"train\", \"valid\", \"test\"]};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional features\n",
    "\n",
    "\n",
    "### Texture features\n",
    "\n",
    "1. First acquire the gray-level co-occurrence matrix G (2 distances, 4 angles = 2*4 = 8 matrices)\n",
    "2. Then, we employ:\n",
    "   - The angular second moment (ASM)\n",
    "   - Entropy (ENT)\n",
    "   - Contrast (CON)\n",
    "   - Correlation (COR)\n",
    "   \n",
    "\n",
    "8 matrices * 4 features each = 32 total features\n",
    "\n",
    "- [Scikit-image texture features](http://scikit-image.org/docs/0.7.0/api/skimage.feature.texture.html)\n",
    "- https://stackoverflow.com/questions/50834170/image-texture-with-skimage\n",
    "- https://stackoverflow.com/questions/51172555/greycomatrix-for-rgb-image\n",
    "- [Calculating **entropy** from GLCM of an image](https://stackoverflow.com/questions/40919936/calculating-entropy-from-glcm-of-an-image)\n",
    "- [Understanding texture properties of a grey-level co-occurrence matrix (GLCM)](https://stackoverflow.com/questions/51463436/understanding-texture-properties-of-a-grey-level-co-occurrence-matrix-glcm)\n",
    "\n",
    "\n",
    "### Color moment features\n",
    "- https://en.wikipedia.org/wiki/Color_moments\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.moment.html\n",
    "- https://stackoverflow.com/questions/38182087/third-order-moment-calculation-numpy\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skew.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [34:04<00:00,  2.28s/it]\n"
     ]
    }
   ],
   "source": [
    "def texture_features(pil_img):\n",
    "    \n",
    "    # Read image in black and white (np array of 2 dimensions)\n",
    "    # img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) # A bit different b&w values\n",
    "    img = pil_img.convert(\"L\")\n",
    "    img = np.array(img)\n",
    "\n",
    "    # Get Gray-Level Co-Occurrence Matrix from the image (2 distances, 4 angles = 2*4 = 8 matrices)\n",
    "    distances  = [1,2]\n",
    "    angles     = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # 0, 45, 90, 135 degree in radians.\n",
    "    glcm = greycomatrix(img, distances, angles)\n",
    "    #print(\"GLCM shape:\", glcm.shape)\n",
    "\n",
    "    # Get properties from glcm. (Entropy feature is not available in the greycoprops method)\n",
    "    properties = ['ASM', 'contrast'] #properties = ['ASM', 'contrast', 'correlation']\n",
    "    some_texture_feats = np.hstack([greycoprops(glcm, prop).ravel() for prop in properties])\n",
    "\n",
    "    entropy_feat = [shannon_entropy(glcm[:,:,x,y])  for x in range(2)   for y in range(4)]\n",
    "\n",
    "    return np.hstack([some_texture_feats, entropy_feat])\n",
    "    \n",
    "    \n",
    "def color_features(pil_img):\n",
    "\n",
    "    np_image = np.array(pil_img)\n",
    "    mean     = np.mean(np_image, axis=(0,1))                           # First color moment (Mean)\n",
    "    std      = np.std(np_image, axis=(0,1))                            # Second color moment (std)\n",
    "    skewness = [skew(np_image[:, :, c].reshape(-1)) for c in range(3)] # Third color moment (Skewness)\n",
    "\n",
    "    return np.hstack([mean, std, skewness])\n",
    "\n",
    "\n",
    "def traditional_features(dataset):\n",
    "    \n",
    "    num_samples = len(dataset)     # 5\n",
    "    \n",
    "    x = np.empty([num_samples, 33]) # 41\n",
    "    y = np.empty([num_samples])\n",
    "    \n",
    "    for i in tqdm(range(num_samples)):\n",
    "        image = dataset[i][0]\n",
    "        label = dataset[i][1]\n",
    "        x[i]  = np.hstack([texture_features(image), color_features(image)])\n",
    "        y[i]  = label\n",
    "        \n",
    "    return x, y\n",
    "\n",
    "# x,y = traditional_features(micro_ds)\n",
    "# x,y = traditional_features(skin_ds[\"test\"])\n",
    "np.save('x.npy', x)\n",
    "np.save('y.npy', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation\n",
    "- [Cross-validation cosidering classes](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators-with-stratification-based-on-class-labels)\n",
    "\n",
    "![img](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_0071.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with traditional features\n",
    "\n",
    "- [scikit-learn](https://scikit-learn.org/stable/modules/svm.html)\n",
    "- [datacamp](https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python)\n",
    "- [dealing with imbalanced classes](https://chrisalbon.com/machine_learning/support_vector_machines/imbalanced_classes_in_svm/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: x = (2828, 33) y = (2828,)\n",
      "================================ Fold 1\n",
      "Accuracy: 0.28771929824561404\n",
      "Confusion matrix:\n",
      " [[  0  49   0   0]\n",
      " [  0  81   0   0]\n",
      " [  0  51   1   0]\n",
      " [  0 103   0   0]]\n",
      "================================ Fold 2\n",
      "Accuracy: 0.28421052631578947\n",
      "Confusion matrix:\n",
      " [[  0  49   0   0]\n",
      " [  0  81   0   0]\n",
      " [  0  52   0   0]\n",
      " [  0 103   0   0]]\n",
      "================================ Fold 3\n",
      "Accuracy: 0.28421052631578947\n",
      "Confusion matrix:\n",
      " [[  0  49   0   0]\n",
      " [  0  81   0   0]\n",
      " [  0  52   0   0]\n",
      " [  0 103   0   0]]\n",
      "================================ Fold 4\n",
      "Accuracy: 0.28421052631578947\n",
      "Confusion matrix:\n",
      " [[  0  49   0   0]\n",
      " [  0  81   0   0]\n",
      " [  0  52   0   0]\n",
      " [  0 103   0   0]]\n",
      "================================ Fold 5\n",
      "Accuracy: 0.36524822695035464\n",
      "Confusion matrix:\n",
      " [[  0   0   0  48]\n",
      " [  0   0   0  80]\n",
      " [  0   0   0  51]\n",
      " [  0   0   0 103]]\n",
      "================================ Fold 6\n",
      "Accuracy: 0.36879432624113473\n",
      "Confusion matrix:\n",
      " [[  0   0   0  48]\n",
      " [  0   0   0  80]\n",
      " [  0   0   1  50]\n",
      " [  0   0   0 103]]\n",
      "================================ Fold 7\n",
      "Accuracy: 0.36298932384341637\n",
      "Confusion matrix:\n",
      " [[  0   0   0  48]\n",
      " [  0   0   0  80]\n",
      " [  0   0   0  51]\n",
      " [  0   0   0 102]]\n",
      "================================ Fold 8\n",
      "Accuracy: 0.36298932384341637\n",
      "Confusion matrix:\n",
      " [[  0   0   0  48]\n",
      " [  0   0   0  80]\n",
      " [  0   0   0  51]\n",
      " [  0   0   0 102]]\n",
      "================================ Fold 9\n",
      "Accuracy: 0.36298932384341637\n",
      "Confusion matrix:\n",
      " [[  0   0   0  48]\n",
      " [  0   0   0  80]\n",
      " [  0   0   0  51]\n",
      " [  0   0   0 102]]\n",
      "================================ Fold 10\n",
      "Accuracy: 0.36298932384341637\n",
      "Confusion matrix:\n",
      " [[  0   0   0  48]\n",
      " [  0   0   0  80]\n",
      " [  0   0   0  51]\n",
      " [  0   0   0 102]]\n"
     ]
    }
   ],
   "source": [
    "cross_valid = StratifiedKFold(n_splits=10)\n",
    "x = np.load('traditionalFeats/his_x.npy')\n",
    "y = np.load('traditionalFeats/his_y.npy')\n",
    "print(\"Data shape: x =\",x.shape, \"y =\", y.shape)\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(cross_valid.split(x, y)):\n",
    "    \n",
    "    ########################################################## GET K-FOLD DATA\n",
    "    x_train, y_train = x[train_index], y[train_index]\n",
    "    x_valid, y_valid = x[valid_index], y[valid_index]\n",
    "    \n",
    "    ########################################################## TRAIN\n",
    "    #svm = SVC(class_weight='balanced', C=1.0, gamma='auto')    # SVM with RBF Kernel\n",
    "    svm = SVC(kernel='rbf', class_weight='balanced', C=1.0, random_state=0, gamma='scale')\n",
    "    svm.fit(x_train, y_train)  # Train the SVM\n",
    "     \n",
    "    ########################################################## EVALUATE\n",
    "    y_pred = svm.predict(x_valid) # Predict the response for test dataset\n",
    "    print(\"================================ Fold\", i+1)\n",
    "    print(\"Accuracy:\",         metrics.accuracy_score(y_valid, y_pred))\n",
    "    print(\"Confusion matrix:\\n\", metrics.confusion_matrix(y_valid, y_pred))\n",
    "    #print(\"\\tPrecision:\", metrics.precision_score(y_valid, y_pred))\n",
    "    #print(\"\\tRecall:\",    metrics.recall_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1696"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "211+30+25+29+20+394+28+59+19+35+241+18+21+42+27+497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1696.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2828*0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Network architecture\n",
    "\n",
    "- [Custom model with fast.ai](https://forums.fast.ai/t/so-you-want-to-create-your-custom-pipeline-with-fastai/17182/11)\n",
    "\n",
    "\n",
    "Input size of `3×140×140`\n",
    "\n",
    "Layer       | Kernel | Stride | Output size\n",
    "------------|--------|--------|------------\n",
    "Convolution | 11×11  |    1   | 32×130×130\n",
    "Convolution | 11×11  |    1   | 32×120×120\n",
    "Max pooling | 5×5    |    2   | 32×58×58\n",
    "Convolution | 9×9    |    1   | 64×50×50\n",
    "Max pooling | 5×5    |    2   | 64×23×23\n",
    "Convolution | 8×8    |    1   | 128×16×16\n",
    "Convolution | 9×9    |    1   | 256×8×8\n",
    "Convolution | 8×8    |    1   | 256×1×1\n",
    "Dense       |    -   |    -   | 4×1×1\n",
    "Softmax     |    -   |    -   | 4×1×1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodingNetwork(nn.Module):\n",
    "    \n",
    "    #Our batch shape for input x is (3, 140, 140)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CodingNetwork, self).__init__()\n",
    "        \n",
    "        #Input channels=3, output channels=32\n",
    "        self.conv1 = nn.Conv2d(3,  32, kernel_size=11, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=11, stride=1, padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=5, stride=2, padding=0)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=9, stride=1, padding=0)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=5, stride=2, padding=0)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(64,  128, kernel_size=8, stride=1, padding=0)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=9, stride=1, padding=0)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=8, stride=1, padding=0)\n",
    "\n",
    "        #4608 input features, 64 output features (see sizing flow below)\n",
    "        self.fc = nn.Linear(256, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Computes the activation of the first convolution\n",
    "        \n",
    "        x = F.relu(self.conv1(x)) # Size changes from (3, 140, 140) to (32, 130, 130)\n",
    "        x = F.relu(self.conv2(x)) # Size changes from (32, 130, 130) to (32, 120, 120)\n",
    "        x = self.pool1(x)         # Size changes from (32, 120, 120) to (32, 58, 58)\n",
    "\n",
    "        x = F.relu(self.conv3(x)) # Size changes from (32, 58, 58) to (64, 50, 50)\n",
    "        x = self.pool2(x)         # Size changes from (64, 50, 50) to (64, 23, 23)\n",
    "\n",
    "        x = F.relu(self.conv4(x)) # Size changes from (64, 23, 23) to (128, 16, 16)\n",
    "        x = F.relu(self.conv5(x)) # Size changes from (128, 16, 16) to (256, 8, 8)\n",
    "        x = F.relu(self.conv6(x)) # Size changes from (256, 8, 8) to (256, 1, 1)\n",
    "\n",
    "        x = x.view(-1, 256)       # Size changes from (256, 1, 1) to (256)\n",
    "        x = self.fc(x)            # Size changes from (256) to (4)\n",
    "        \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CodingNetwork()\n",
    "\n",
    "x = torch.randn(16, 3, 140, 140)\n",
    "output = model(x)\n",
    "\n",
    "\n",
    "learn = Learner(my_data_bunch, model, metrics=accuracy)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Stratified CV requires explicitely passing a suitable y.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cc2c0e426b92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmicro_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;31m#y_proba = net.predict_proba(X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skorch\\classifier.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# this is actually a pylint bug:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;31m# https://github.com/PyCQA/pylint/issues/1085\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNeuralNetClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    840\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'on_train_begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         dataset_train, dataset_valid = self.get_split_datasets(\n\u001b[1;32m--> 724\u001b[1;33m             X, y, **fit_params)\n\u001b[0m\u001b[0;32m    725\u001b[0m         on_epoch_kwargs = {\n\u001b[0;32m    726\u001b[0m             \u001b[1;34m'dataset_train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mget_split_datasets\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_split\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m             dataset_train, dataset_valid = self.train_split(\n\u001b[1;32m-> 1170\u001b[1;33m                 dataset, y, **fit_params)\n\u001b[0m\u001b[0;32m   1171\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[0mdataset_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skorch\\dataset.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, dataset, y, groups)\u001b[0m\n\u001b[0;32m    278\u001b[0m             \"Stratified CV requires explicitely passing a suitable y.\")\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstratified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mbad_y_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Stratified CV requires explicitely passing a suitable y."
     ]
    }
   ],
   "source": [
    "mean       = [0.485, 0.456, 0.406] #[0.5, 0.5, 0.5]\n",
    "std        = [0.229, 0.224, 0.225] #[0.5, 0.5, 0.5]\n",
    "train_tmfs =  transforms.Compose([transforms.RandomCrop(420),\n",
    "                                  transforms.Resize(140),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.RandomVerticalFlip(),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean, std)])\n",
    "\n",
    "micro_ds.transforms = train_tmfs\n",
    "trainloader = torch.utils.data.DataLoader(micro_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "##################################### TRAIN WITH SKORCH\n",
    "net = NeuralNetClassifier(\n",
    "    CodingNetwork,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    batch_size=64\n",
    "    dataset\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(X=micro_ds, y=None)\n",
    "#y_proba = net.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
