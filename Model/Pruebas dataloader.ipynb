{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI framework by Javi based in PyTorch: 0.4.1\n"
     ]
    }
   ],
   "source": [
    "from javIA_oop import *\n",
    "import cv2\n",
    "from albumentations import Compose, RandomCrop, Normalize, Flip, Resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "ver https://github.com/albu/albumentations/blob/master/notebooks/migrating_from_torchvision_to_albumentations.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_transf = transforms.Compose([\n",
    "\ttransforms.Resize((256, 256)), \n",
    "\ttransforms.RandomCrop(224),\n",
    "\ttransforms.RandomHorizontalFlip(),\n",
    "\ttransforms.RandomVerticalFlip(),\n",
    "\t#transforms.RandomRotation(degrees=90),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize(\n",
    "\t\tmean=[0.485, 0.456, 0.406],\n",
    "\t\tstd=[0.229, 0.224, 0.225],\n",
    "\t)\n",
    "])\n",
    "\n",
    "\n",
    "albu_transf = Compose([\n",
    "\tResize(256, 256), \n",
    "\tRandomCrop(224, 224),\n",
    "\t#HorizontalFlip(),\n",
    "\t#VerticalFlip(p=0.5),\n",
    "\tFlip(p=0.5),\n",
    "\tNormalize(\n",
    "\t\tmean=[0.485, 0.456, 0.406],\n",
    "\t\tstd=[0.229, 0.224, 0.225],\n",
    "\t)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIL + torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data hyperparameters\n",
    "data_dir_ssd = pathlib.Path(\"C:/Users/Javi/Desktop/Datasets/histologyDS2828\")\n",
    "data_dir_hdd = pathlib.Path(\"D:/Datasets/TFM/histologyDS2828\")\n",
    "imgs_dir     = data_dir_ssd / \"imgs\"\n",
    "csv_file     = data_dir_ssd / \"imageClasses.txt\"\n",
    "\n",
    "\n",
    "class histologyDataset(torch.utils.data.Dataset):\n",
    "\n",
    "\tdef __init__(self, imgs_dir, csv_file, transform=None):\n",
    "\t\tself.df       = pd.read_csv(csv_file, header=None, delim_whitespace=True, names=['Image', 'Label'])\n",
    "\t\tself.imgs_dir = imgs_dir\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.df)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_name = imgs_dir / (self.df.iloc[idx, 0])\n",
    "\t\timage    = PIL.Image.open(img_name)\n",
    "\t\tif self.transform:\n",
    "\t\t\timage = self.transform(image)\n",
    "\t\tlabel    = self.df.iloc[idx, 1] - 1\n",
    "\t\treturn image, label\n",
    "\n",
    "dataset1 = histologyDataset(imgs_dir, csv_file, torch_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIL + albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data hyperparameters\n",
    "data_dir_ssd = pathlib.Path(\"C:/Users/Javi/Desktop/Datasets/histologyDS2828\")\n",
    "data_dir_hdd = pathlib.Path(\"D:/Datasets/TFM/histologyDS2828\")\n",
    "imgs_dir     = data_dir_ssd / \"imgs\"\n",
    "csv_file     = data_dir_ssd / \"imageClasses.txt\"\n",
    "\n",
    "\n",
    "class histologyDataset2(torch.utils.data.Dataset):\n",
    "\n",
    "\tdef __init__(self, imgs_dir, csv_file, transform=None):\n",
    "\t\tself.df       = pd.read_csv(csv_file, header=None, delim_whitespace=True, names=['Image', 'Label'])\n",
    "\t\tself.imgs_dir = imgs_dir\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.df)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_name = imgs_dir / (self.df.iloc[idx, 0])\n",
    "\t\timage    = PIL.Image.open(img_name)\n",
    "\t\tif self.transform:\n",
    "\t\t\timage_np = np.array(image)    # Convert PIL image to numpy array\n",
    "\t\t\taugmented = self.transform(image=image_np) # Apply transformations\n",
    "\t\t\timage = augmented['image']\n",
    "\t\tlabel    = self.df.iloc[idx, 1] - 1\n",
    "\t\treturn image, label\n",
    "\n",
    "dataset2 = histologyDataset2(imgs_dir, csv_file, albu_transf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV + albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data hyperparameters\n",
    "data_dir_ssd = pathlib.Path(\"C:/Users/Javi/Desktop/Datasets/histologyDS2828\")\n",
    "data_dir_hdd = pathlib.Path(\"D:/Datasets/TFM/histologyDS2828\")\n",
    "imgs_dir     = data_dir_ssd / \"imgs\"\n",
    "csv_file     = data_dir_ssd / \"imageClasses.txt\"\n",
    "\n",
    "\n",
    "class histologyDataset3(torch.utils.data.Dataset):\n",
    "\n",
    "\tdef __init__(self, imgs_dir, csv_file, transform=None):\n",
    "\t\tself.df       = pd.read_csv(csv_file, header=None, delim_whitespace=True, names=['Image', 'Label'])\n",
    "\t\tself.imgs_dir = imgs_dir\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.df)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_name = imgs_dir / (self.df.iloc[idx, 0])\n",
    "\t\timage = cv2.imread(str(img_name))\n",
    "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\t\tif self.transform:\n",
    "\t\t\taugmented = self.transform(image=image)\n",
    "\t\t\timage = augmented['image']\n",
    "\t\tlabel    = self.df.iloc[idx, 1] - 1\n",
    "\t\treturn image, label\n",
    "\n",
    "dataset3 = histologyDataset3(imgs_dir, csv_file, albu_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 #128\n",
    "loader1 = torch.utils.data.DataLoader(dataset1, batch_size=batch_size)\n",
    "loader2 = torch.utils.data.DataLoader(dataset2, batch_size=batch_size)\n",
    "loader3 = torch.utils.data.DataLoader(dataset3, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 45/45 [00:18<00:00,  2.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 45/45 [00:25<00:00,  2.26it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 45/45 [00:21<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL + torchvision:     18.482799291610718\n",
      "PIL + albumentations:  25.819448709487915\n",
      "CV2 + albumentations:  21.685729265213013\n"
     ]
    }
   ],
   "source": [
    "t = Timer()\n",
    "\n",
    "for batch in tqdm(loader1):\n",
    "    pass\n",
    "time1 = t()\n",
    "for batch in tqdm(loader2):\n",
    "    pass\n",
    "time2 = t()\n",
    "for batch in tqdm(loader3):\n",
    "    pass\n",
    "time3 = t()\n",
    "\n",
    "print(\"PIL + torchvision:    \", time1)\n",
    "print(\"PIL + albumentations: \", time2)\n",
    "print(\"CV2 + albumentations: \", time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
